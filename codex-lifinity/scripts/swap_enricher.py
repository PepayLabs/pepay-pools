"""Produce a swap-focused ledger from Lifinity instruction extracts."""
from __future__ import annotations

import argparse
import logging
from pathlib import Path
from typing import Dict, List

import pandas as pd
import yaml

from .config import PROCESSED_DATA_DIR


def load_instruction_ledger(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"Instruction ledger missing: {path}")
    df = pd.read_csv(path)
    required = {"tx_id", "slot", "block_time", "is_inner", "discriminator", "accounts"}
    missing = sorted(required - set(df.columns))
    if missing:
        raise ValueError(f"Instruction ledger missing columns {missing}")
    return df


def load_discriminator_map(path: Path) -> Dict[str, Dict]:
    if not path.exists():
        logging.warning("Discriminator map not found: %s", path)
        return {}
    data = yaml.safe_load(path.read_text()) or {}
    return {key.lower(): value or {} for key, value in data.items()}


def expand_accounts(account_field: str) -> List[str]:
    if not account_field:
        return []
    return [entry.strip() for entry in account_field.split(",") if entry.strip()]


def build_swap_rows(df: pd.DataFrame, discriminator_map: Dict[str, Dict]) -> pd.DataFrame:
    records: List[Dict] = []
    for _, row in df.iterrows():
        discriminator = str(row["discriminator"]).lower()
        mapping = discriminator_map.get(discriminator, {})
        accounts = expand_accounts(row.get("accounts", ""))
        records.append({
            "tx_id": row["tx_id"],
            "slot": row["slot"],
            "block_time": row["block_time"],
            "is_inner": row["is_inner"],
            "discriminator": discriminator,
            "instruction_name": mapping.get("name", "unknown"),
            "account_count": len(accounts),
            "accounts": accounts,
            "account_labels": mapping.get("accounts"),
            "notes": mapping.get("notes", "TODO: decode data schema"),
        })
    ledger = pd.DataFrame(records)
    ledger.sort_values(["slot", "tx_id"], inplace=True)
    return ledger


def serialise_accounts(ledger: pd.DataFrame) -> pd.DataFrame:
    df = ledger.copy()
    df["accounts"] = df["accounts"].apply(lambda values: ",".join(values))
    df["account_labels"] = df["account_labels"].apply(lambda values: ",".join(str(v) for v in values) if isinstance(values, list) else "")
    return df


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Build enriched swap ledger from Lifinity instructions")
    parser.add_argument(
        "--instructions",
        type=Path,
        default=Path(PROCESSED_DATA_DIR) / "lifinity_instructions.csv",
        help="CSV generated by scripts/enrich_swaps.py",
    )
    parser.add_argument(
        "--map",
        type=Path,
        default=Path(__file__).resolve().parent / "discriminators.yaml",
        help="YAML file describing decoded discriminators",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path(PROCESSED_DATA_DIR) / "tx_samples_enriched.csv",
        help="Destination CSV path",
    )
    parser.add_argument("--verbose", action="store_true")
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    logging.basicConfig(level=logging.DEBUG if args.verbose else logging.INFO)

    instructions = load_instruction_ledger(args.instructions)
    discriminator_map = load_discriminator_map(args.map)
    ledger = build_swap_rows(instructions, discriminator_map)
    serialised = serialise_accounts(ledger)

    args.output.parent.mkdir(parents=True, exist_ok=True)
    serialised.to_csv(args.output, index=False)
    logging.info("Enriched swap ledger written to %s (%d rows)", args.output, len(serialised))


if __name__ == "__main__":
    main()
